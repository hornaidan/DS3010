{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsjq366HA18T"
   },
   "source": [
    "# Project 1 : Collecting Data from Twitter\n",
    "\n",
    "Start Date: 3/21/2022, Due Date: 3/31/2022, **BEFORE the beginning of class**\n",
    "\n",
    "## **NOTE: There are *always* last minute issues submitting the case studies.  DO NOT WAIT UNTIL THE LAST MINUTE!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31lTqAzjA18W"
   },
   "source": [
    "<img src=\"https://logos-download.com/wp-content/uploads/2016/02/Twitter_Logo_new-700x569.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRnGkCSRA18X"
   },
   "source": [
    "**Individual Assignment:** Please EDIT this cell and add your name\n",
    "\n",
    "    Aidan Horn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxc6cgPOA18Y"
   },
   "source": [
    "**Suggested Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book \"Mining the Social Web\" can help a lot if you get stuck. \n",
    "* In fact, it is intentional that many of these questions can be answered directly from there (except for question 4)!\n",
    "* The idea is to ease you into the case studies :-)\n",
    "\n",
    "**Don't forget!**\n",
    "* You will need to install the twitter library to access the Twitter API\n",
    " * pip install twitter\n",
    "* NOTE: There is a package called \"python-twitter\" which will not work with this notebook!\n",
    "\n",
    "\n",
    "**NOTE**\n",
    "* **Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-uJJaulA18Y"
   },
   "source": [
    "# Problem 1 (20 points): Sampling Twitter Data with the Search API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWqIK-0VA18Y"
   },
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Search API to sample a collection of tweets about this topic. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHlfqylGDAEo",
    "outputId": "661f68ac-11be-4144-a801-497f17deb3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter in c:\\users\\horna\\anaconda3\\lib\\site-packages (1.19.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "3DcAmeG9A18Z"
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import json\n",
    "from time import gmtime, strftime\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    # Prof. Paffenroth has a developer account for the class.  He will provide the Twitter access tokens for\n",
    "    # each team\n",
    "    # See https://developer.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'oJpnhPtow417C4xHxnzZ8icfS'\n",
    "    CONSUMER_SECRET = 'i7eVuKl5LFQ1jhyRX3xyjH6HYgwEZtq0Av6YOBtC965PJ8cR9g'\n",
    "    OAUTH_TOKEN = '1042905448528064512-z4LzLfbtR0CvPNoEmiQe1MfRD16aOB'\n",
    "    OAUTH_TOKEN_SECRET = 'eb7MCzjwxH7zqxLsDbIJLapXS5j1tp79UkGPYH4h1FMu0'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "twitter_api = oauth_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-01 03:17:25\n",
      "Length of statuses 86\n",
      "Length of statuses 178\n",
      "Length of statuses 273\n",
      "Length of statuses 356\n",
      "Length of statuses 445\n",
      "Latest tweet @ClayTravis @clayandbuck @TuckerCarlson @CNN @FoxNews @MSNBC @DNC @RNC @HillaryClinton @RealCandaceO… https://t.co/JZ3IR9ZVSF\n"
     ]
    }
   ],
   "source": [
    "print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
    "\n",
    "q = 'POTUS'\n",
    "count = 200\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "search_results = twitter_api.search.tweets(q=q, count=count, tweet_mode = 'extended')\n",
    "\n",
    "statuses = search_results['statuses']\n",
    "#print([d['text'] for d in search_results['statuses']])\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"Length of statuses\", len(statuses))\n",
    "    try:\n",
    "        next_results = search_results['search_metadata']['next_results']\n",
    "    except (KeyError): # No more results when next_results doesn't exist\n",
    "        break\n",
    "    kwargs = dict([ kv.split('=') for kv in next_results[1:].split(\"&\") ])\n",
    "    search_results = twitter_api.search.tweets(**kwargs)\n",
    "    statuses += search_results['statuses']\n",
    "\n",
    "tweet = statuses[-1]['retweeted_status']['full_text'] if statuses[-1]['retweeted'] else statuses[-1]['text']\n",
    "print(\"Latest tweet \" + tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old length of tweet list: 4791\n",
      "New length of tweet list: 5326\n",
      "Length of tweet list after removing duplicates: 5326\n",
      "Latest tweet @ClayTravis @clayandbuck @TuckerCarlson @CNN @FoxNews @MSNBC @DNC @RNC @HillaryClinton @RealCandaceO… https://t.co/JZ3IR9ZVSF\n"
     ]
    }
   ],
   "source": [
    "#File in local directory\n",
    "filename = \"statuses_POTUS.json\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    #Get list of json formatted tweet data\n",
    "    list_s = json.load(file)\n",
    "    \n",
    "    print(f\"Old length of tweet list: {len(list_s)}\")\n",
    "    #Extend list with list of statuses returned by twitter API search call in cell above\n",
    "    list_s.extend(statuses)\n",
    "    \n",
    "    print(f\"New length of tweet list: {len(list_s)}\")\n",
    "    \n",
    "    #Use tweet id's to detect any duplicates in the list of statuses\n",
    "    #Necessary due to occasional failure to detect duplicate tweets using 'not in unique_s'\n",
    "    IDs = [sub['id'] for sub in list_s]\n",
    "    duplicates = [ID for ID in IDs if IDs.count(ID) > 1]\n",
    "    unique_duplicates = list(set(duplicates))\n",
    "    \n",
    "    #Create new list to append all non-duplicate entries\n",
    "    unique_s = []\n",
    "\n",
    "    for s in list_s:\n",
    "        if s not in unique_s and s['id'] not in unique_duplicates:\n",
    "            unique_s.append(s)\n",
    "    \n",
    "    print(f\"Length of tweet list after removing duplicates: {len(unique_s)}\")\n",
    "    \n",
    "with open(filename, 'w') as file:\n",
    "    \n",
    "    #Write list of unique statuses to file in json format\n",
    "    json.dump(unique_s, file, indent = 1)\n",
    "\n",
    "print(\"Latest tweet \" + unique_s[-1]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgU_ryKOA18d"
   },
   "source": [
    "### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: POTUS \n",
    "\n",
    "\n",
    "* The total number of tweets collected:  4000+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUNy7CEJA18d"
   },
   "source": [
    "* -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHvwKm5sA18e"
   },
   "source": [
    "# Problem 2 (20 points): Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "V_ZHKBRuA18e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = \"statuses_POTUS.json\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    list_s = json.load(file)  \n",
    "\n",
    "list_t = []\n",
    "\n",
    "#Some tweets in list are were added before tweet_mode was extended in the API search call\n",
    "#The content of these tweets are indexed at either \"text\" or \"full_text\"\n",
    "\n",
    "for s in list_s:\n",
    "    try:\n",
    "        t = s['text']\n",
    "    except(KeyError):\n",
    "        t = s['full_text']\n",
    "    list_t.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tigray</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>vp</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>today</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>us</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>people</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>till</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>emmett</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>act</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>know</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>biden</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>want</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>lynching</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>americans</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>prime</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>minister</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>president</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>trump</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>back</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>sign</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>antilynching</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>long</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>aid</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>history</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>nation</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>needed</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>time</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>brave</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>need</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Count\n",
       "1         tigray    405\n",
       "2             vp    346\n",
       "3            000    314\n",
       "4          today    286\n",
       "5             us    285\n",
       "6         people    281\n",
       "7           till    266\n",
       "8         emmett    264\n",
       "9            act    254\n",
       "10          know    242\n",
       "11         biden    242\n",
       "12          want    237\n",
       "13      lynching    223\n",
       "14     americans    218\n",
       "15         prime    215\n",
       "16      minister    215\n",
       "17     president    212\n",
       "18         trump    209\n",
       "19          back    206\n",
       "20          sign    199\n",
       "21  antilynching    193\n",
       "22          long    192\n",
       "23           aid    191\n",
       "24       history    180\n",
       "25        nation    174\n",
       "26        needed    172\n",
       "27             1    171\n",
       "28          time    169\n",
       "29         brave    169\n",
       "30          need    163"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#most of the common words will be artifacts such as https, punctuation, or very common words\n",
    "#we will use a stopword set from nltk modified to include other unwanted words to filter the tweet text\n",
    "#we will also use a word tokenizer to filter out punctuation marks\n",
    "#finally, we will ensure all text is lowercase\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['https','co','amp','rt','potus'])\n",
    "filtered_words = [w.lower() for t in list_t \n",
    "                  for w in tokenizer.tokenize(t) \n",
    "                  if not w.lower() in stop_words]\n",
    "\n",
    "c = Counter(filtered_words)\n",
    "#print(c.most_common()[:30])\n",
    "\n",
    "df_count = pd.DataFrame(data = c.most_common()[:30], columns=[\"Word\", \"Count\"], index=list(range(1,31)))\n",
    "df_count.to_csv('df_count.csv')\n",
    "df_count.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = \" \".join(word for word in df_count.Word)\n",
    "wordcloud = WordCloud(background_color=\"white\").generate(text)\n",
    "wordcloud.to_file(\"top_30_words.png\")\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMigKzFlA18e"
   },
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "JrxgbEBRA18f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>24536</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>RT @POTUS: I want to be clear: We will defend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21024</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>RT @POTUS: Putin has the gall to say he is “de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>20417</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>RT @POTUS: After my predecessor’s fiscal misma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>19181</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>RT @POTUS: I visited Ukrainian refugees who ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>17954</td>\n",
       "      <td>ZelenskyyUa</td>\n",
       "      <td>RT @ZelenskyyUa: Had a substantive conversatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>17727</td>\n",
       "      <td>AVindman</td>\n",
       "      <td>RT @AVindman: This was an historical speech fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>14316</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>RT @POTUS: I just signed the Emmett Till Antil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>13635</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>RT @POTUS: This afternoon, I met with members ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>11611</td>\n",
       "      <td>senadormx</td>\n",
       "      <td>RT @senadormx: Yo le propongo a @KenSalazar  d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>11228</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>RT @POTUS: We are engaged anew in a great batt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Screen Name                                               Text\n",
       "0   24536        POTUS  RT @POTUS: I want to be clear: We will defend ...\n",
       "1   21024        POTUS  RT @POTUS: Putin has the gall to say he is “de...\n",
       "6   20417        POTUS  RT @POTUS: After my predecessor’s fiscal misma...\n",
       "50  19181        POTUS  RT @POTUS: I visited Ukrainian refugees who ha...\n",
       "55  17954  ZelenskyyUa  RT @ZelenskyyUa: Had a substantive conversatio...\n",
       "56  17727     AVindman  RT @AVindman: This was an historical speech fo...\n",
       "58  14316        POTUS  RT @POTUS: I just signed the Emmett Till Antil...\n",
       "91  13635        POTUS  RT @POTUS: This afternoon, I met with members ...\n",
       "92  11611    senadormx  RT @senadormx: Yo le propongo a @KenSalazar  d...\n",
       "93  11228        POTUS  RT @POTUS: We are engaged anew in a great batt..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"statuses_POTUS.json\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    list_s = json.load(file)\n",
    "\n",
    "rt = []\n",
    "\n",
    "for s in list_s:\n",
    "    try:\n",
    "        if 'retweeted_status' in s:\n",
    "            rt.append((s['retweet_count'], s['retweeted_status']['user']['screen_name'], s['text']))\n",
    "        \n",
    "    except(KeyError):\n",
    "        if 'retweeted_status' in s:        \n",
    "            rt.append((s['retweet_count'], s['retweeted_status']['user']['screen_name'], s['full_text']))\n",
    "            \n",
    "df_rt = pd.DataFrame(data = sorted(rt, reverse = True), columns=[\"Count\", \"Screen Name\", \"Text\"])\n",
    "df_rt = df_rt.drop_duplicates(subset = ['Text'])\n",
    "df_rt.to_csv('df_rt.csv')\n",
    "df_rt.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbUOQT32A18f"
   },
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "DKYkobrzA18f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tigray</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AllowAccessToTigray</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SupportHR6600</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IC</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>AntilynchingAct</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>CancelStudentDebt</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TigrayGenocide</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>strisciaforpeace</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Hashtag  Count\n",
       "1                Tigray    200\n",
       "2   AllowAccessToTigray     64\n",
       "3         SupportHR6600     59\n",
       "4                    IC     58\n",
       "5       AntilynchingAct     57\n",
       "6     CancelStudentDebt     48\n",
       "7             Ethiopian     35\n",
       "8        TigrayGenocide     33\n",
       "9              Ethiopia     31\n",
       "10     strisciaforpeace     30"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"statuses_POTUS.json\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    list_s = json.load(file)\n",
    "\n",
    "ht = [hashtag['text'] for s in list_s for hashtag in s['entities']['hashtags']]\n",
    "\n",
    "c = Counter(ht)\n",
    "\n",
    "#um = [user_mention['name'] for s in list_s for user_mention in s['entities']['hashtags']]\n",
    "\n",
    "df_ht = pd.DataFrame(data = c.most_common()[:10], columns = ['Hashtag','Count'], index = list(range(1,11)))\n",
    "df_ht.to_csv('df_ht.csv')\n",
    "df_ht.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Mention</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>President Biden</td>\n",
       "      <td>3575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Vice President Kamala Harris</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Boris Johnson</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Secretary Antony Blinken</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Emmanuel Macron</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Olaf Scholz</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>USAID</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NATO</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Bobby L. Rush</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    User Mention  Count\n",
       "1                President Biden   3575\n",
       "2   Vice President Kamala Harris    336\n",
       "3                  Boris Johnson    150\n",
       "4       Secretary Antony Blinken    109\n",
       "5                      Joe Biden    103\n",
       "6                Emmanuel Macron    100\n",
       "7                    Olaf Scholz     91\n",
       "8                          USAID     87\n",
       "9                           NATO     85\n",
       "10                 Bobby L. Rush     79"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"statuses_POTUS.json\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    list_s = json.load(file)\n",
    "\n",
    "um = [user_mention['name'] for s in list_s for user_mention in s['entities']['user_mentions']]\n",
    "\n",
    "c = Counter(um)\n",
    "\n",
    "df_um = pd.DataFrame(data = c.most_common()[:10], columns = ['User Mention','Count'], index = list(range(1,11)))\n",
    "df_um.to_csv('df_um.csv')\n",
    "df_um.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLEC3fX_A18g"
   },
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 3 (20 points): Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wTKbSAnA18g"
   },
   "source": [
    "* choose a popular twitter user who has many followers. Since some popular users have millions of followers, it may take a very long time to get the follower list. Hence, we recommend you choosing a \"popular\" user with a reasonable number of followers, that your program can handle.\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def tweepy_oauth_login():\n",
    "    # Prof. Paffenroth has a developer account for the class.  He will provide the Twitter access tokens for\n",
    "    # each team\n",
    "    # See https://developer.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'oJpnhPtow417C4xHxnzZ8icfS'\n",
    "    CONSUMER_SECRET = 'i7eVuKl5LFQ1jhyRX3xyjH6HYgwEZtq0Av6YOBtC965PJ8cR9g'\n",
    "    OAUTH_TOKEN = '1042905448528064512-z4LzLfbtR0CvPNoEmiQe1MfRD16aOB'\n",
    "    OAUTH_TOKEN_SECRET = 'eb7MCzjwxH7zqxLsDbIJLapXS5j1tp79UkGPYH4h1FMu0'\n",
    "    \n",
    "    auth = tweepy.OAuth1UserHandler(\n",
    "       CONSUMER_KEY, CONSUMER_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "    \n",
    "    return tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "api = tweepy_oauth_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "screen_name = \"BobbyBroccole\"\n",
    "\n",
    "#followers = api.get_followers(screen_name = screen_name, count = 200)\n",
    "\n",
    "users = tweepy.Cursor(api.get_followers, screen_name=screen_name, count = 200).items(1206)\n",
    "u = []\n",
    "while True:\n",
    "    try:\n",
    "        user = next(users)\n",
    "    except tweepy.TweepyException:\n",
    "        time.sleep(60*15)\n",
    "        user = next(users)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    #print(user.screen_name)\n",
    "    u.append((user.id,user.screen_name))\n",
    "\n",
    "df_fl = pd.DataFrame(data = u, columns = [\"ID\",\"Screen Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Screen Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>757634771853934592</td>\n",
       "      <td>Nynebark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1077703096317415430</td>\n",
       "      <td>braillecollage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1330157180994064387</td>\n",
       "      <td>tolzasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1329663294567813121</td>\n",
       "      <td>ThatNaughtyKat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>948653033407369216</td>\n",
       "      <td>unniFI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1350199414544072709</td>\n",
       "      <td>bojojojo02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1360385187251539971</td>\n",
       "      <td>IamAlexChao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3965371</td>\n",
       "      <td>eduardoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1399259474079014917</td>\n",
       "      <td>SteelwoolOcto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1362214222877192194</td>\n",
       "      <td>3892534627a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>863366473225469952</td>\n",
       "      <td>LunaIsNotABoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2199107545</td>\n",
       "      <td>vgxlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>880596538816430082</td>\n",
       "      <td>ionmars10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>247165354</td>\n",
       "      <td>Alejandroxvg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>853717332</td>\n",
       "      <td>galaxybraingood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1855726963</td>\n",
       "      <td>garudaphoenix0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3255566258</td>\n",
       "      <td>DeathLetterReds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>730078888001458176</td>\n",
       "      <td>LinkunfromPolan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>140233311</td>\n",
       "      <td>NeroBearo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>47356269</td>\n",
       "      <td>Lbsjr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>439945045</td>\n",
       "      <td>Soccerluc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1206074604076167168</td>\n",
       "      <td>Cloakingwolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1015743487025614852</td>\n",
       "      <td>blazebrxghton_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1481278897</td>\n",
       "      <td>SoLongMeatbags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1349848270919626752</td>\n",
       "      <td>tinymedia_nick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1342731874515513345</td>\n",
       "      <td>Sleepyfork1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>416171959</td>\n",
       "      <td>marasversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1042214127614214150</td>\n",
       "      <td>linq__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1276298547743166464</td>\n",
       "      <td>TachYouVeryMuch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1012217467505168384</td>\n",
       "      <td>bolli242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID      Screen Name\n",
       "0    757634771853934592         Nynebark\n",
       "1   1077703096317415430   braillecollage\n",
       "2   1330157180994064387         tolzasso\n",
       "3   1329663294567813121   ThatNaughtyKat\n",
       "4    948653033407369216           unniFI\n",
       "5   1350199414544072709       bojojojo02\n",
       "6   1360385187251539971      IamAlexChao\n",
       "7               3965371         eduardoe\n",
       "8   1399259474079014917    SteelwoolOcto\n",
       "9   1362214222877192194      3892534627a\n",
       "10   863366473225469952    LunaIsNotABoy\n",
       "11           2199107545            vgxlr\n",
       "12   880596538816430082        ionmars10\n",
       "13            247165354     Alejandroxvg\n",
       "14            853717332  galaxybraingood\n",
       "15           1855726963   garudaphoenix0\n",
       "16           3255566258  DeathLetterReds\n",
       "17   730078888001458176  LinkunfromPolan\n",
       "18            140233311        NeroBearo\n",
       "19             47356269            Lbsjr\n",
       "20            439945045        Soccerluc\n",
       "21  1206074604076167168     Cloakingwolf\n",
       "22  1015743487025614852   blazebrxghton_\n",
       "23           1481278897   SoLongMeatbags\n",
       "24  1349848270919626752   tinymedia_nick\n",
       "25  1342731874515513345      Sleepyfork1\n",
       "26            416171959     marasversion\n",
       "27  1042214127614214150           linq__\n",
       "28  1276298547743166464  TachYouVeryMuch\n",
       "29  1012217467505168384         bolli242"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fl.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "screen_name = \"BobbyBroccole\"\n",
    "\n",
    "users = tweepy.Cursor(api.get_friends, screen_name=screen_name, count = 200).items(363)\n",
    "u = []\n",
    "while True:\n",
    "    try:\n",
    "        user = next(users)\n",
    "    except tweepy.TweepyException:\n",
    "        time.sleep(60*15)\n",
    "        user = next(users)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    #print(user.screen_name)\n",
    "    u.append((user.id,user.screen_name))\n",
    "\n",
    "df_fr = pd.DataFrame(data = u, columns = [\"ID\",\"Screen Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Screen Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1506689287278014469</td>\n",
       "      <td>PoliticDrip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1411723858181251074</td>\n",
       "      <td>ampol_moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1504956528914309122</td>\n",
       "      <td>ClubPhotos_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>741809888368566272</td>\n",
       "      <td>GreatCheshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>840848485</td>\n",
       "      <td>FredInTheKnud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>36201559</td>\n",
       "      <td>VorosTwins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>984862457217933318</td>\n",
       "      <td>KevinPerjurer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>318993598</td>\n",
       "      <td>Q_Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2616274436</td>\n",
       "      <td>CJMacaulay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>993692561863667712</td>\n",
       "      <td>OOHKAYEYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2883608207</td>\n",
       "      <td>northandnavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>922379257971580929</td>\n",
       "      <td>IzzzyzzzArt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3180191078</td>\n",
       "      <td>XiranJayZhao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>10690422</td>\n",
       "      <td>digitalcoleman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1353619003340709889</td>\n",
       "      <td>jordanxtheresa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>236999725</td>\n",
       "      <td>davidgross_man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>544268841</td>\n",
       "      <td>ShawnMenard1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>794967538321002497</td>\n",
       "      <td>Defunctland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2604749205</td>\n",
       "      <td>munecatmusic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>856999355370291200</td>\n",
       "      <td>tunicgame</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID     Screen Name\n",
       "0   1506689287278014469     PoliticDrip\n",
       "1   1411723858181251074    ampol_moment\n",
       "2   1504956528914309122     ClubPhotos_\n",
       "3    741809888368566272   GreatCheshire\n",
       "4             840848485   FredInTheKnud\n",
       "5              36201559      VorosTwins\n",
       "6    984862457217933318   KevinPerjurer\n",
       "7             318993598        Q_Review\n",
       "8            2616274436      CJMacaulay\n",
       "9    993692561863667712       OOHKAYEYE\n",
       "10           2883608207    northandnavy\n",
       "11   922379257971580929     IzzzyzzzArt\n",
       "12           3180191078    XiranJayZhao\n",
       "13             10690422  digitalcoleman\n",
       "14  1353619003340709889  jordanxtheresa\n",
       "15            236999725  davidgross_man\n",
       "16            544268841    ShawnMenard1\n",
       "17   794967538321002497     Defunctland\n",
       "18           2604749205    munecatmusic\n",
       "19   856999355370291200       tunicgame"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fr.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGOvRwzxA18h"
   },
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "FGOM-EKTA18i"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Screen Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>318993598</td>\n",
       "      <td>Q_Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>70739029</td>\n",
       "      <td>jon_bois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>993692561863667712</td>\n",
       "      <td>OOHKAYEYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29472053</td>\n",
       "      <td>Hbomberguy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2330900772</td>\n",
       "      <td>GC__Vazquez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  Screen Name\n",
       "0           318993598     Q_Review\n",
       "1            70739029     jon_bois\n",
       "2  993692561863667712    OOHKAYEYE\n",
       "3            29472053   Hbomberguy\n",
       "4          2330900772  GC__Vazquez"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection = pd.merge(df_fl,df_fr,how='inner')\n",
    "\n",
    "intersection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4B53GdUzA18i"
   },
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 4 (20 points): Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Question:\n",
    "#### *In order to improve a brand's Twitter presence, how does one prioritize which Tweets at the company to which a social media manager should respond directly?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Case:\n",
    "\n",
    "* Let's say a business, such as Nestle, feels they lack a social media presence on Twitter. \n",
    "\n",
    "* In order to establish a notable awareness among users and a good reputation, they believe they should increase their user engagement by responding to Tweets at their account. \n",
    "\n",
    "* However, they want to find a way to prioritize content that is emotionally charged, either strongly positive or strongly negative, as well as increase engagement by replying to Tweets that will increase in popularity. \n",
    "* Therefore, they need a system that can aggregate recent tweets and rank Tweets by the predicted impact, which can be estimated from the intensity of the language and the number of retweets and favorites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How could Twitter data help a company decide how to spend its resources?\n",
    "\n",
    "* Twitter is a useful tool for extracting public sentiment\n",
    "* Marketing departments spend millions to determine how the public feel about a company and how to improve a brand's image.\n",
    "* However, small scale interactions with consumers or members of the public are often more effective than large scale advertisments and PR campaigns, but these efforts require a high level of engagement thus a high amount of resources necessary.\n",
    "* We can more efficiently allocate these resources if we can specifically target individuals who are already engaging with the brand and who may act as a nexus for others to engage.\n",
    "* Thus Twitter data can help identify these individuals and improve the decision making abilities of a company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Start by pulling recent tweets directed at the brand's twitter handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "FomaD-F0A18i"
   },
   "outputs": [],
   "source": [
    "q = \"@Nestle\"\n",
    "\n",
    "search_results = twitter_api.search.tweets(q=q, count=200, tweet_mode = 'extended', lang='en')\n",
    "\n",
    "statuses = search_results['statuses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create a database of relevant information about the tweet\n",
    "\n",
    "> Filter out Retweets to avoid duplicate text bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Favorited Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1509632999020642315</td>\n",
       "      <td>Tenacious “T” #VoteBlueToEndTheViolence 🌻</td>\n",
       "      <td>Stop @nestle @ArrowheadWater from taking milli...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1509630993455583236</td>\n",
       "      <td>ПАПАndopulo</td>\n",
       "      <td>Hey, @Nestle @Nestle_es @NestleColombia @Nestl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1509729253482450944</td>\n",
       "      <td>Dr. Magdalena Whoolery</td>\n",
       "      <td>Beware @Nestle’s “help”4Ukraine. “Nestlé, the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1509629920561012739</td>\n",
       "      <td>k</td>\n",
       "      <td>@Nestle @IrishTimes Russia is a murderer and a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1509635996572270611</td>\n",
       "      <td>RafmansKitchen</td>\n",
       "      <td>Out of coffee and creamer?  No biggie we got y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                                Screen Name  \\\n",
       "22  1509632999020642315  Tenacious “T” #VoteBlueToEndTheViolence 🌻   \n",
       "23  1509630993455583236                                ПАПАndopulo   \n",
       "0   1509729253482450944                     Dr. Magdalena Whoolery   \n",
       "26  1509629920561012739                                          k   \n",
       "20  1509635996572270611                             RafmansKitchen   \n",
       "\n",
       "                                                Tweet  Retweet Count  \\\n",
       "22  Stop @nestle @ArrowheadWater from taking milli...              1   \n",
       "23  Hey, @Nestle @Nestle_es @NestleColombia @Nestl...              1   \n",
       "0   Beware @Nestle’s “help”4Ukraine. “Nestlé, the ...              0   \n",
       "26  @Nestle @IrishTimes Russia is a murderer and a...              0   \n",
       "20  Out of coffee and creamer?  No biggie we got y...              0   \n",
       "\n",
       "    Favorited Count  \n",
       "22                3  \n",
       "23                0  \n",
       "0                 1  \n",
       "26                0  \n",
       "20                0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply_data = [(r['id_str'],\n",
    "                r['user']['name'],\n",
    "                r['full_text'],\n",
    "                r['retweet_count'],\n",
    "                r['favorite_count']) for r in statuses if r['full_text'][0:2] != 'RT']\n",
    "\n",
    "df_replies = pd.DataFrame(data = reply_data, \n",
    "                          columns = ['ID','Screen Name','Tweet','Retweet Count','Favorited Count'])\n",
    "\n",
    "df_replies.to_csv('df_replies.csv')\n",
    "df_replies.sort_values(by = 'Retweet Count', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we can run sentiment intensity analysis on the tweet content, we just want the compound score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\horna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Favorited Count</th>\n",
       "      <th>Compound SA Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1509729253482450944</td>\n",
       "      <td>Dr. Magdalena Whoolery</td>\n",
       "      <td>Beware @Nestle’s “help”4Ukraine. “Nestlé, the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1509724594919288833</td>\n",
       "      <td>Wear A Mask and Please take the vaccine!</td>\n",
       "      <td>@AnonOpsSE @Nestle @Gizmodo Dear Anonymous \\n@...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1509719066046603273</td>\n",
       "      <td>Dr. Magdalena Whoolery</td>\n",
       "      <td>@AnonOpsSE @Nestle @Gizmodo Trust me. Nestlé a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1509707111529332741</td>\n",
       "      <td>ꀘꃅ4ꋪꂵꍏ ꀘ0ꂵꍏ</td>\n",
       "      <td>@AnonOpsSE @Nestle @Gizmodo your parents didn'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1509706896810389508</td>\n",
       "      <td>FD Svensson 🍀 #FCKPTN</td>\n",
       "      <td>@AnonOpsSE @Nestle @Gizmodo It's not just abou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                               Screen Name  \\\n",
       "0  1509729253482450944                    Dr. Magdalena Whoolery   \n",
       "1  1509724594919288833  Wear A Mask and Please take the vaccine!   \n",
       "2  1509719066046603273                    Dr. Magdalena Whoolery   \n",
       "3  1509707111529332741                               ꀘꃅ4ꋪꂵꍏ ꀘ0ꂵꍏ   \n",
       "4  1509706896810389508                     FD Svensson 🍀 #FCKPTN   \n",
       "\n",
       "                                               Tweet  Retweet Count  \\\n",
       "0  Beware @Nestle’s “help”4Ukraine. “Nestlé, the ...              0   \n",
       "1  @AnonOpsSE @Nestle @Gizmodo Dear Anonymous \\n@...              0   \n",
       "2  @AnonOpsSE @Nestle @Gizmodo Trust me. Nestlé a...              0   \n",
       "3  @AnonOpsSE @Nestle @Gizmodo your parents didn'...              0   \n",
       "4  @AnonOpsSE @Nestle @Gizmodo It's not just abou...              0   \n",
       "\n",
       "   Favorited Count  Compound SA Score  \n",
       "0                1            -0.7251  \n",
       "1                0             0.3818  \n",
       "2                1             0.6597  \n",
       "3                0             0.3096  \n",
       "4                0            -0.9042  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "df_replies['Compound SA Score'] = [sid.polarity_scores(t)['compound'] for t in df_replies['Tweet']]\n",
    "df_replies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.19, 'neu': 0.81, 'pos': 0.0, 'compound': -0.6608}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(df_replies['Tweet'][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We want to estimate the amount of impact a tweet may have by creating a score using retweet count, favorited count, and the SA score\n",
    "\n",
    "> We wnat to priortize retweets over favorites since they will engage with more users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Favorited Count</th>\n",
       "      <th>Compound SA Score</th>\n",
       "      <th>Impact Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1509729253482450944</td>\n",
       "      <td>Dr. Magdalena Whoolery</td>\n",
       "      <td>Beware @Nestle’s “help”4Ukraine. “Nestlé, the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7251</td>\n",
       "      <td>-0.906375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1509724594919288833</td>\n",
       "      <td>Wear A Mask and Please take the vaccine!</td>\n",
       "      <td>@AnonOpsSE @Nestle @Gizmodo Dear Anonymous \\n@...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.381800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1509719066046603273</td>\n",
       "      <td>Dr. Magdalena Whoolery</td>\n",
       "      <td>@AnonOpsSE @Nestle @Gizmodo Trust me. Nestlé a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.824625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1509707111529332741</td>\n",
       "      <td>ꀘꃅ4ꋪꂵꍏ ꀘ0ꂵꍏ</td>\n",
       "      <td>@AnonOpsSE @Nestle @Gizmodo your parents didn'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0.309600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1509706896810389508</td>\n",
       "      <td>FD Svensson 🍀 #FCKPTN</td>\n",
       "      <td>@AnonOpsSE @Nestle @Gizmodo It's not just abou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9042</td>\n",
       "      <td>-0.904200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                               Screen Name  \\\n",
       "0  1509729253482450944                    Dr. Magdalena Whoolery   \n",
       "1  1509724594919288833  Wear A Mask and Please take the vaccine!   \n",
       "2  1509719066046603273                    Dr. Magdalena Whoolery   \n",
       "3  1509707111529332741                               ꀘꃅ4ꋪꂵꍏ ꀘ0ꂵꍏ   \n",
       "4  1509706896810389508                     FD Svensson 🍀 #FCKPTN   \n",
       "\n",
       "                                               Tweet  Retweet Count  \\\n",
       "0  Beware @Nestle’s “help”4Ukraine. “Nestlé, the ...              0   \n",
       "1  @AnonOpsSE @Nestle @Gizmodo Dear Anonymous \\n@...              0   \n",
       "2  @AnonOpsSE @Nestle @Gizmodo Trust me. Nestlé a...              0   \n",
       "3  @AnonOpsSE @Nestle @Gizmodo your parents didn'...              0   \n",
       "4  @AnonOpsSE @Nestle @Gizmodo It's not just abou...              0   \n",
       "\n",
       "   Favorited Count  Compound SA Score  Impact Score  \n",
       "0                1            -0.7251     -0.906375  \n",
       "1                0             0.3818      0.381800  \n",
       "2                1             0.6597      0.824625  \n",
       "3                0             0.3096      0.309600  \n",
       "4                0            -0.9042     -0.904200  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_replies['Impact Score'] = (df_replies['Retweet Count'] + 1\n",
    "                              + df_replies['Favorited Count']/4) * df_replies['Compound SA Score']\n",
    "df_replies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally we want to sort this database by the magnitude of the impact score. Positive tweets and negative tweets have an equal weight in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Favorited Count</th>\n",
       "      <th>Compound SA Score</th>\n",
       "      <th>Impact Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1509630079374082049</td>\n",
       "      <td>Anonymous Operations</td>\n",
       "      <td>It's lovely how @Nestle completely ignore the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.6066</td>\n",
       "      <td>-1.061550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1509685084252786690</td>\n",
       "      <td>Mike's One of Millions</td>\n",
       "      <td>@aaronhoyland As long as you steer clear of @N...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>1.025325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1509692534393643013</td>\n",
       "      <td>Suzie Gray</td>\n",
       "      <td>Let’s BOYCOTT @Nestle !  Nestle is a Murderer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9103</td>\n",
       "      <td>-0.910300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1509729253482450944</td>\n",
       "      <td>Dr. Magdalena Whoolery</td>\n",
       "      <td>Beware @Nestle’s “help”4Ukraine. “Nestlé, the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7251</td>\n",
       "      <td>-0.906375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1509706896810389508</td>\n",
       "      <td>FD Svensson 🍀 #FCKPTN</td>\n",
       "      <td>@AnonOpsSE @Nestle @Gizmodo It's not just abou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9042</td>\n",
       "      <td>-0.904200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID             Screen Name  \\\n",
       "24  1509630079374082049    Anonymous Operations   \n",
       "7   1509685084252786690  Mike's One of Millions   \n",
       "6   1509692534393643013              Suzie Gray   \n",
       "0   1509729253482450944  Dr. Magdalena Whoolery   \n",
       "4   1509706896810389508   FD Svensson 🍀 #FCKPTN   \n",
       "\n",
       "                                                Tweet  Retweet Count  \\\n",
       "24  It's lovely how @Nestle completely ignore the ...              0   \n",
       "7   @aaronhoyland As long as you steer clear of @N...              0   \n",
       "6   Let’s BOYCOTT @Nestle !  Nestle is a Murderer ...              0   \n",
       "0   Beware @Nestle’s “help”4Ukraine. “Nestlé, the ...              0   \n",
       "4   @AnonOpsSE @Nestle @Gizmodo It's not just abou...              0   \n",
       "\n",
       "    Favorited Count  Compound SA Score  Impact Score  \n",
       "24                3            -0.6066     -1.061550  \n",
       "7                 3             0.5859      1.025325  \n",
       "6                 0            -0.9103     -0.910300  \n",
       "0                 1            -0.7251     -0.906375  \n",
       "4                 0            -0.9042     -0.904200  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_priority = df_replies.iloc[(-df_replies['Impact Score'].abs()).argsort()]\n",
    "df_priority.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This experiment has produced a worthwhile tweet to respond to. A legitmate customer concern with a larger number of retweets and favorites, indicating public sentiment is aligned with this persons opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCrHmit6A18j"
   },
   "source": [
    "* -----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "**What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10-15 minutes talk) to present about the project. We will ask two students which are randomly selected to present their results in class for this project. \n",
    "\n",
    "* **Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "**How to submit:**\n",
    "\n",
    "        Please submit in canvas.\n",
    "\n",
    "#### We auto-process the submissions so make sure your subject line is *exactly*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_y_VpkSA18j"
   },
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "**Totoal Points: 100**\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "**Notebook results:**\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API.  Come up with a business question and describe how Twitter data can help you answer that question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "**Slides (for presentation): Story-telling**\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "CaseStudy1_Twitter_answer.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
